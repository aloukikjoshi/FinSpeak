"""
FinSpeak Streamlit Web Application
Speech-driven Investment Q&A Assistant
"""

import os
import tempfile
import queue
from typing import Optional, Dict

import streamlit as st
import numpy as np

try:
    from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
    import av
    WEBRTC_AVAILABLE = True
except ImportError:
    WEBRTC_AVAILABLE = False

from fin_speak.config import Config
from fin_speak.stt import transcribe, preprocess_audio
from fin_speak.nlp import detect_intent, extract_fund
from fin_speak.kb import (
    match_fund,
    get_latest_nav,
    get_fund_info,
    compute_return,
    get_all_funds,
)
from fin_speak.tts import synthesize_text, get_audio_bytes


def generate_answer(
    transcript: str,
    intent: str,
    fund_id: Optional[str],
    fund_name: Optional[str],
    period_months: Optional[int],
    nav_data: Optional[Dict] = None,
    return_data: Optional[Dict] = None,
) -> str:
    """
    Generate natural language answer based on intent and data
    
    Args:
        transcript: Original user query
        intent: Detected intent
        fund_id: Matched fund ID
        fund_name: Matched fund name
        period_months: Time period in months
        nav_data: Latest NAV data
        return_data: Return computation results
        
    Returns:
        Natural language answer
    """
    if fund_id is None:
        return "I couldn't identify which fund you're asking about. Could you please specify the fund name more clearly?"
    
    if intent == "get_nav":
        if nav_data:
            return (
                f"The latest NAV for {fund_name} as of {nav_data['date']} "
                f"is ${nav_data['nav']:.2f}."
            )
        else:
            return f"I couldn't find NAV data for {fund_name}."
    
    elif intent == "get_return":
        if return_data:
            period = return_data['period_months']
            pct_return = return_data['percentage_return']
            abs_return = return_data['absolute_return']
            
            direction = "gained" if pct_return > 0 else "lost"
            
            return (
                f"{fund_name} has {direction} {abs(pct_return):.2f}% "
                f"over the past {period:.1f} months, from ${return_data['start_nav']:.2f} "
                f"on {return_data['start_date']} to ${return_data['end_nav']:.2f} "
                f"on {return_data['end_date']}. This represents an absolute change of "
                f"${abs_return:.2f}."
            )
        else:
            return f"I couldn't compute returns for {fund_name}."
    
    elif intent == "explain_change":
        return (
            f"I can provide the performance data for {fund_name}, but detailed explanations "
            f"of market changes require analysis of market conditions, economic factors, "
            f"and fund-specific events. I recommend consulting detailed fund reports or "
            f"a financial advisor for comprehensive analysis."
        )
    
    else:
        return (
            "I can help you with:\n"
            "- Getting the current NAV of a fund\n"
            "- Computing returns over a period\n"
            "- Basic performance queries\n"
            f"You asked: '{transcript}'\n"
            "Could you rephrase your question?"
        )


def main():
    """Main Streamlit application"""
    
    # Page configuration
    st.set_page_config(
        page_title="FinSpeak - Investment Q&A",
        page_icon="üìä",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Title and description
    st.title("üìä FinSpeak")
    st.subheader("Speech-driven Investment Q&A Assistant")
    st.markdown("*Ask questions about fund NAVs and returns using your voice or text*")
    
    # Sidebar configuration
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        # Model selection
        st.subheader("Models")
        whisper_model = st.selectbox(
            "Whisper Model",
            ["tiny", "base", "small", "medium", "large"],
            index=2  # Default to 'small'
        )
        Config.WHISPER_MODEL_SIZE = whisper_model
        
        # Azure Speech option
        use_azure = st.checkbox(
            "Use Azure Speech",
            value=Config.use_azure_speech(),
            help="Requires AZURE_SPEECH_KEY and AZURE_SPEECH_REGION in .env"
        )
        if use_azure and not (Config.AZURE_SPEECH_KEY and Config.AZURE_SPEECH_REGION):
            st.warning("‚ö†Ô∏è Azure Speech credentials not found in .env file")
        Config.USE_AZURE_SPEECH = use_azure
        
        st.divider()
        
        # About
        st.subheader("‚ÑπÔ∏è About")
        st.markdown(
            """
            FinSpeak uses:
            - **Whisper** for speech-to-text
            - **Rule-based NLP** for intent detection
            - **Fuzzy matching** for fund identification
            - **gTTS** for text-to-speech
            """
        )
        
        st.divider()
        
        # Available funds
        with st.expander("üìã Available Funds"):
            try:
                funds = get_all_funds()
                for fund in funds:
                    st.text(f"‚Ä¢ {fund['fund_name']}")
            except Exception as e:
                st.error(f"Error loading funds: {e}")
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üé§ Input")
        
        # Input method tabs
        if WEBRTC_AVAILABLE:
            input_tab1, input_tab2, input_tab3 = st.tabs(["üé§ Record Audio", "üìÅ Upload Audio", "‚å®Ô∏è Text Input"])
        else:
            input_tab1, input_tab2 = st.tabs(["üìÅ Upload Audio", "‚å®Ô∏è Text Input"])
            input_tab3 = None
        
        # Initialize session state for recorded audio
        if 'recorded_audio' not in st.session_state:
            st.session_state.recorded_audio = None
        
        audio_file = None
        recorded_audio_data = None
        
        if WEBRTC_AVAILABLE:
            with input_tab1:
                st.markdown("**Record your question using your microphone**")
                
                # Audio processor class for capturing audio
                class AudioProcessor(AudioProcessorBase):
                    def __init__(self):
                        self.audio_buffer = []
                        self.sample_rate = 16000
                    
                    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
                        # Capture audio frames
                        audio_array = frame.to_ndarray()
                        self.audio_buffer.append(audio_array)
                        return frame
                
                webrtc_ctx = webrtc_streamer(
                    key="speech-to-text",
                    mode=WebRtcMode.SENDONLY,
                    audio_receiver_size=1024,
                    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
                    media_stream_constraints={"video": False, "audio": True},
                )
                
                if webrtc_ctx.audio_receiver:
                    try:
                        audio_frames = webrtc_ctx.audio_receiver.get_frames(timeout=1)
                        if audio_frames:
                            # Combine audio frames into single array
                            audio_data = []
                            for frame in audio_frames:
                                audio_data.append(frame.to_ndarray())
                            if audio_data:
                                combined = np.concatenate(audio_data, axis=1)
                                st.session_state.recorded_audio = combined
                                st.success("‚úÖ Audio recorded! Click 'Process Query' to transcribe.")
                    except queue.Empty:
                        pass
                
                if st.session_state.recorded_audio is not None:
                    st.info("üéß Audio recording captured. Ready to process.")
                    recorded_audio_data = st.session_state.recorded_audio
            
            with input_tab2:
                audio_file = st.file_uploader(
                    "Upload audio file (WAV or MP3)",
                    type=["wav", "mp3", "m4a"],
                    help="Upload an audio file with your question"
                )
                
                if audio_file:
                    st.audio(audio_file, format="audio/wav")
            
            with input_tab3:
                text_input = st.text_area(
                    "Or type your question",
                    placeholder="What is the current NAV of Vanguard S&P 500 Fund?",
                    help="Type your question as text"
                )
        else:
            with input_tab1:
                audio_file = st.file_uploader(
                    "Upload audio file (WAV or MP3)",
                    type=["wav", "mp3", "m4a"],
                    help="Upload an audio file with your question"
                )
                
                if audio_file:
                    st.audio(audio_file, format="audio/wav")
            
            with input_tab2:
                text_input = st.text_area(
                    "Or type your question",
                    placeholder="What is the current NAV of Vanguard S&P 500 Fund?",
                    help="Type your question as text"
                )
        
        # Process button
        process_button = st.button("üöÄ Process Query", type="primary", use_container_width=True)
    
    with col2:
        st.header("üí° Example Queries")
        st.markdown(
            """
            - "What is the current NAV of Vanguard S&P 500 Fund?"
            - "Show me 6-month returns for Fidelity Growth Fund"
            - "How has Wellington Fund performed over 1 year?"
            - "Get me the latest price of PIMCO Total Return Fund"
            """
        )
    
    # Process the query
    if process_button:
        transcript = None
        
        # Get transcript
        with st.spinner("Processing..."):
            tmp_path = None
            try:
                if recorded_audio_data is not None:
                    # Save recorded audio to temp file
                    import soundfile as sf
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                        tmp_path = tmp_file.name
                    # Flatten and save as mono
                    audio_mono = recorded_audio_data.flatten() if recorded_audio_data.ndim > 1 else recorded_audio_data
                    sf.write(tmp_path, audio_mono, Config.SAMPLE_RATE)
                    
                    st.info("üéß Transcribing recorded audio...")
                    transcript = transcribe(tmp_path)
                    # Clear the recorded audio after processing
                    st.session_state.recorded_audio = None
                    
                elif audio_file:
                    # Save uploaded file temporarily
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                        tmp_file.write(audio_file.read())
                        tmp_path = tmp_file.name
                    
                    # Preprocess audio to 16kHz mono
                    processed_path = preprocess_audio(tmp_path)
                    
                    st.info("üéß Transcribing audio...")
                    transcript = transcribe(processed_path)
                    
                elif text_input:
                    transcript = text_input
                else:
                    st.warning("‚ö†Ô∏è Please provide audio or text input")
                    return
            
            except Exception as e:
                st.error(f"‚ùå Error processing input: {e}")
                if Config.DEBUG:
                    st.exception(e)
                return
            finally:
                # Cleanup temp file
                if tmp_path and os.path.exists(tmp_path):
                    os.unlink(tmp_path)
        
        # Display results
        if transcript:
            st.divider()
            st.header("üìã Results")
            
            # Show transcript
            st.subheader("üìù Transcript")
            st.info(transcript)
            
            # Detect intent
            try:
                intent_result = detect_intent(transcript)
                intent = intent_result['intent']
                intent_confidence = intent_result['confidence']
                period_months = intent_result.get('period_months')
                
                st.subheader("üéØ Detected Intent")
                col_a, col_b = st.columns(2)
                with col_a:
                    st.metric("Intent", intent.replace("_", " ").title())
                with col_b:
                    st.metric("Confidence", f"{intent_confidence * 100:.1f}%")
                
            except Exception as e:
                st.error(f"‚ùå Error detecting intent: {e}")
                if Config.DEBUG:
                    st.exception(e)
                return
            
            # Extract fund
            try:
                fund_name, fund_confidence = extract_fund(transcript)
                
                st.subheader("üè¢ Matched Fund")
                if fund_name:
                    col_c, col_d = st.columns(2)
                    with col_c:
                        st.metric("Fund Name", fund_name)
                    with col_d:
                        st.metric("Match Confidence", f"{fund_confidence * 100:.1f}%")
                    
                    fund_id = match_fund(fund_name)
                    
                    if fund_id:
                        fund_info = get_fund_info(fund_id)
                        if fund_info:
                            st.caption(
                                f"**Category:** {fund_info['category']} | "
                                f"**Ticker:** {fund_info['ticker']}"
                            )
                else:
                    st.warning("‚ö†Ô∏è Could not identify fund from query")
                    fund_id = None
                
            except Exception as e:
                st.error(f"‚ùå Error extracting fund: {e}")
                if Config.DEBUG:
                    st.exception(e)
                fund_id = None
                fund_name = None
            
            # Fetch data and generate answer
            nav_data = None
            return_data = None
            
            if fund_id:
                try:
                    if intent == "get_nav":
                        nav_data = get_latest_nav(fund_id)
                        
                        if nav_data:
                            st.subheader("üìä Latest NAV")
                            col_e, col_f = st.columns(2)
                            with col_e:
                                st.metric("NAV", f"${nav_data['nav']:.2f}")
                            with col_f:
                                st.metric("Date", nav_data['date'])
                    
                    elif intent == "get_return":
                        if period_months is None:
                            period_months = 12  # Default
                        
                        return_data = compute_return(fund_id, period_months)
                        
                        if return_data:
                            st.subheader("üìà Return Analysis")
                            col_g, col_h, col_i = st.columns(3)
                            with col_g:
                                pct_return = return_data['percentage_return']
                                st.metric(
                                    "Return",
                                    f"{pct_return:.2f}%",
                                    delta=f"${return_data['absolute_return']:.2f}"
                                )
                            with col_h:
                                st.metric("Start NAV", f"${return_data['start_nav']:.2f}")
                            with col_i:
                                st.metric("End NAV", f"${return_data['end_nav']:.2f}")
                            
                            st.caption(
                                f"Period: {return_data['start_date']} to {return_data['end_date']} "
                                f"({return_data['period_months']:.1f} months)"
                            )
                
                except Exception as e:
                    st.error(f"‚ùå Error fetching data: {e}")
                    if Config.DEBUG:
                        st.exception(e)
            
            # Generate answer
            try:
                answer = generate_answer(
                    transcript=transcript,
                    intent=intent,
                    fund_id=fund_id,
                    fund_name=fund_name,
                    period_months=period_months,
                    nav_data=nav_data,
                    return_data=return_data,
                )
                
                st.subheader("üí¨ Answer")
                st.success(answer)
                
                # Generate TTS
                with st.spinner("üîä Generating audio..."):
                    try:
                        with tempfile.NamedTemporaryFile(
                            delete=False, suffix=".mp3"
                        ) as tmp_audio:
                            audio_path = tmp_audio.name
                        
                        synthesize_text(answer, audio_path)
                        
                        # Read audio bytes before displaying to avoid file access issues
                        audio_bytes = get_audio_bytes(audio_path)
                        st.audio(audio_bytes, format="audio/mp3")
                        
                        # Cleanup after reading bytes
                        if os.path.exists(audio_path):
                            os.unlink(audio_path)
                    
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Could not generate audio: {e}")
                
            except Exception as e:
                st.error(f"‚ùå Error generating answer: {e}")
                if Config.DEBUG:
                    st.exception(e)
    
    # Footer
    st.divider()
    st.caption(
        "üìÑ **Resume Bullet:** Built FinSpeak, a speech-driven investment Q&A assistant "
        "using Whisper STT, rule-based NLP, and Streamlit, enabling voice-based queries "
        "for fund NAVs and returns with 85%+ intent detection accuracy."
    )


if __name__ == "__main__":
    main()
